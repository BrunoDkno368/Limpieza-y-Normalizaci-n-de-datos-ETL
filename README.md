# Proyecto ETL ‚Äì Limpieza, Normalizaci√≥n y Validaci√≥n de Datos con Python

## üìå Descripci√≥n general

Este repositorio documenta un proyecto completo de **ETL (Extract, Transform, Load)** aplicado a un dataset con **datos sucios, inconsistentes y no estructurados**, simulando un escenario real de trabajo en **An√°lisis de Datos / Data Analytics**.

El objetivo principal es demostrar competencias t√©cnicas en:

* Procesos ETL con Python
* Limpieza y calidad de datos (Data Cleaning & Data Quality)
* Normalizaci√≥n y estandarizaci√≥n de informaci√≥n
* Aplicaci√≥n de reglas de negocio
* Preparaci√≥n de datos para an√°lisis, reporting o carga en bases de datos

Este tipo de procesos es habitual en entornos de **Business Intelligence, Data Analytics, Data Engineering Junior** y proyectos de anal√≠tica aplicada.

---

## üõ†Ô∏è Tecnolog√≠as y herramientas

* **Python 3**
* **Pandas** (manipulaci√≥n y transformaci√≥n de datos)
* **NumPy** (operaciones num√©ricas)
* **Google Colab** (entorno de desarrollo)
* **CSV** como fuente de datos

**Palabras clave:** ETL, Data Cleaning, Data Wrangling, Pandas, Python, Data Quality, Data Analytics, Business Intelligence

---

## üìÇ Estructura del dataset

Dataset original con informaci√≥n de clientes y compras.

Columnas:

* `id`
* `nombre`
* `edad`
* `fecha_registro`
* `monto_compra`
* `provincia`

Dimensiones iniciales:

* **Filas:** 11
* **Columnas:** 6

---

## üîÑ Proceso ETL

### 1Ô∏è‚É£ Extract (Extracci√≥n de datos)

* Lectura del archivo CSV utilizando Pandas.
* Creaci√≥n de una copia del DataFrame original para preservar la fuente de datos.
* Inspecci√≥n inicial de dimensiones, tipos de datos y valores √∫nicos.

**Objetivo:** garantizar trazabilidad y evitar modificaciones sobre los datos crudos.

---

### 2Ô∏è‚É£ Transform (Transformaci√≥n y limpieza de datos)

Esta es la fase central del proyecto, donde se aplican m√∫ltiples t√©cnicas de **Data Cleaning**.

---

### üîπ Limpieza y normalizaci√≥n de columnas de texto

**Columnas trabajadas:** `nombre`, `provincia`

Problemas detectados:

* Espacios innecesarios
* Diferencias de may√∫sculas/min√∫sculas
* Valores nulos o vac√≠os
* Errores tipogr√°ficos
* Uso de s√≠mbolos especiales
* Inconsistencias sem√°nticas

Acciones aplicadas:

* Conversi√≥n a tipo string
* Eliminaci√≥n de espacios al inicio y final
* Normalizaci√≥n de capitalizaci√≥n
* Reemplazo de valores nulos por `Sin datos`
* Limpieza de caracteres no alfab√©ticos
* Correcci√≥n manual de valores inconsistentes

Ejemplos:

* `Ju@n` ‚Üí `Juan`
* `Mar ia` ‚Üí `Mar√≠a`
* `Tucuman` ‚Üí `Tucum√°n`
* `Bs As` ‚Üí `Buenos Aires`

**Conceptos clave:** Text Normalization, Data Standardization, Data Consistency

---

### üîπ Limpieza de la columna `edad`

Problemas detectados:

* Valores no num√©ricos (`treinta`)
* Edades negativas
* Edades fuera de rango (`200`)
* Valores nulos

Reglas de negocio aplicadas:

* Edad v√°lida entre **0 y 120 a√±os**

Transformaciones realizadas:

* Conversi√≥n a num√©rico con control de errores
* Reemplazo de valores inv√°lidos por `NaN`
* Imputaci√≥n de valores faltantes mediante la **media**
* Conversi√≥n final a entero

**Conceptos clave:** Data Validation, Outlier Detection, Missing Values Imputation

---

### üîπ Limpieza de la columna `monto_compra`

Problemas detectados:

* Formatos num√©ricos mixtos (`1.200,30`, `1500.5`)
* Valores negativos
* Valores extremadamente altos
* Celdas vac√≠as o con espacios

Reglas de negocio aplicadas:

* No se permiten montos negativos
* Montos mayores a **90.000** se consideran at√≠picos

Transformaciones realizadas:

* Normalizaci√≥n de separadores decimales
* Conversi√≥n a tipo num√©rico
* Detecci√≥n y eliminaci√≥n de outliers
* Imputaci√≥n de valores faltantes con la media redondeada

**Conceptos clave:** Numeric Parsing, Outliers, Business Rules, Data Quality

---

### üîπ Limpieza de la columna `fecha_registro`

Problemas detectados:

* M√∫ltiples formatos de fecha
* Fechas inv√°lidas
* Fechas con texto en espa√±ol
* Fechas con componente horario

Transformaciones realizadas:

* Conversi√≥n inicial a texto
* Traducci√≥n de meses del espa√±ol al ingl√©s
* Unificaci√≥n de separadores
* Correcci√≥n manual de casos puntuales
* Conversi√≥n final a tipo `datetime`

**Conceptos clave:** Date Parsing, Time Series Preparation, Data Standardization

---

### 3Ô∏è‚É£ Load (Carga de datos)

* Eliminaci√≥n de columnas auxiliares
* Consolidaci√≥n del DataFrame final
* Dataset listo para:

  * An√°lisis exploratorio (EDA)
  * Visualizaci√≥n
  * Reporting
  * Carga en bases de datos

---

## ‚úÖ Resultado final

El dataset resultante:

* Presenta **consistencia sem√°ntica y estructural**
* Tiene **tipos de datos correctos**
* Cumple reglas b√°sicas de negocio
* Est√° preparado para an√°lisis y toma de decisiones

---

## üéØ Objetivos del proyecto

* Simular un proceso ETL real
* Aplicar buenas pr√°cticas de limpieza de datos
* Demostrar pensamiento anal√≠tico
* Fortalecer un portfolio profesional en Data Analytics

---

## üöÄ Mejoras futuras

* Automatizaci√≥n del pipeline ETL
* Validaciones con tests de calidad de datos
* An√°lisis exploratorio de datos (EDA)
* Visualizaciones
* Persistencia en base de datos (SQL)

---

## üë§ Autor

**Bruno Arga√±araz**
Analista de Datos
Tucum√°n, Argentina
LinkedIn: [https://www.linkedin.com/in/bruno-arga%C3%B1araz-726a4a199/](https://www.linkedin.com/in/bruno-arga%C3%B1araz-726a4a199/)

---
